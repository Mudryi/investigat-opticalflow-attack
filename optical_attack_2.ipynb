{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optical_attack_2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONnKGvXpx9YezMD7C3ckQs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mudryi/investigat-opticalflow-attack/blob/main/optical_attack_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImA3PmK4_GnJ",
        "outputId": "02c3d963-a22d-4a92-ddcd-8adf6f8c2c8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.15.4 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueFbJDJi8viX",
        "outputId": "4f036927-b4a1-4494-b1c9-681943b02caf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.15.4 in /usr/local/lib/python3.7/dist-packages (1.15.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzGpstUV46qq",
        "outputId": "c42f4aa5-446e-4015-a2b7-6ab55fa28b16"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hZZWKwS46t1",
        "outputId": "ae115e8c-336e-4429-91ee-a879b661b59c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n",
            "Requirement already satisfied: mmcv-full in /usr/local/lib/python3.7/dist-packages (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.15.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.3)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (2.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (3.13)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (0.32.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full) (3.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/open-mmlab/mmflow.git\n",
        "%cd mmflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDQn5Xu12_2a",
        "outputId": "27ccaab0-8db7-4fcf-b7e4-db44a361440b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'mmflow' already exists and is not an empty directory.\n",
            "/content/mmflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements/build.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfoAzRbQ4KMo",
        "outputId": "1c9a6f4c-da23-41ab-ab7a-c56a59baa4e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements/build.txt (line 2)) (1.15.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -v -e ."
      ],
      "metadata": {
        "id": "Ww02KxnC4Ne0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ec1660-4a72-4c10-b2ff-c793d83c2b92"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 21.1.3 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n",
            "Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/include/python3.7/UNKNOWN\n",
            "sysconfig: /usr/include/python3.7m/UNKNOWN\n",
            "Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/bin\n",
            "sysconfig: /usr/bin\n",
            "Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local\n",
            "sysconfig: /usr\n",
            "Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\n",
            "Non-user install because site-packages writeable\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-zum129eh\n",
            "Created temporary directory: /tmp/pip-req-tracker-k0_myvzg\n",
            "Initialized build tracking at /tmp/pip-req-tracker-k0_myvzg\n",
            "Created build tracker: /tmp/pip-req-tracker-k0_myvzg\n",
            "Entered build tracker: /tmp/pip-req-tracker-k0_myvzg\n",
            "Created temporary directory: /tmp/pip-install-p_v29y5x\n",
            "Obtaining file:///content/mmflow\n",
            "  Added file:///content/mmflow to build tracker '/tmp/pip-req-tracker-k0_myvzg'\n",
            "    Running setup.py (path:/content/mmflow/setup.py) egg_info for package from file:///content/mmflow\n",
            "    Created temporary directory: /tmp/pip-pip-egg-info-bh4gb3yw\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-pip-egg-info-bh4gb3yw/mmflow.egg-info\n",
            "    writing /tmp/pip-pip-egg-info-bh4gb3yw/mmflow.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-pip-egg-info-bh4gb3yw/mmflow.egg-info/dependency_links.txt\n",
            "    writing requirements to /tmp/pip-pip-egg-info-bh4gb3yw/mmflow.egg-info/requires.txt\n",
            "    writing top-level names to /tmp/pip-pip-egg-info-bh4gb3yw/mmflow.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-bh4gb3yw/mmflow.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    warning: no files found matching 'mmflow/VERSION'\n",
            "    warning: no files found matching 'mmflow/.mim/demo/*/*'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-bh4gb3yw/mmflow.egg-info/SOURCES.txt'\n",
            "  Source in /content/mmflow has version 0.2.0, which satisfies requirement mmflow==0.2.0 from file:///content/mmflow\n",
            "  Removed mmflow==0.2.0 from file:///content/mmflow from build tracker '/tmp/pip-req-tracker-k0_myvzg'\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmflow==0.2.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmflow==0.2.0) (1.15.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmflow==0.2.0) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmflow==0.2.0) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmflow==0.2.0) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmflow==0.2.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmflow==0.2.0) (0.11.0)\n",
            "Created temporary directory: /tmp/pip-unpack-dum5l84b\n",
            "Installing collected packages: mmflow\n",
            "  Attempting uninstall: mmflow\n",
            "    Found existing installation: mmflow 0.2.0\n",
            "    Not sure how to uninstall: mmflow 0.2.0 - Check: /content/mmflow\n",
            "    Can't uninstall 'mmflow'. No files were found to uninstall.\n",
            "  Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/mmflow\n",
            "  sysconfig: /usr/include/python3.7m/mmflow\n",
            "  Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\n",
            "  Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\n",
            "  Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\n",
            "  Running setup.py develop for mmflow\n",
            "    Running command /usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/content/mmflow/setup.py'\"'\"'; __file__='\"'\"'/content/mmflow/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\n",
            "    running develop\n",
            "    running egg_info\n",
            "    writing mmflow.egg-info/PKG-INFO\n",
            "    writing dependency_links to mmflow.egg-info/dependency_links.txt\n",
            "    writing requirements to mmflow.egg-info/requires.txt\n",
            "    writing top-level names to mmflow.egg-info/top_level.txt\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    warning: no files found matching 'mmflow/VERSION'\n",
            "    warning: no files found matching 'mmflow/.mim/demo/*/*'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file 'mmflow.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "    Creating /usr/local/lib/python3.7/dist-packages/mmflow.egg-link (link to .)\n",
            "    mmflow 0.2.0 is already the active version in easy-install.pth\n",
            "\n",
            "    Installed /content/mmflow\n",
            "Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/include/python3.7/UNKNOWN\n",
            "sysconfig: /usr/include/python3.7m/UNKNOWN\n",
            "Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/bin\n",
            "sysconfig: /usr/bin\n",
            "Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local\n",
            "sysconfig: /usr\n",
            "Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\n",
            "Successfully installed mmflow-0.2.0\n",
            "Removed build tracker: '/tmp/pip-req-tracker-k0_myvzg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mmflow.apis import inference_model, init_model\n",
        "from mmflow.datasets import visualize_flow, write_flow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import tqdm\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9yUHhC7DioNv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda:0'\n",
        "\n",
        "path_to_data = '/content/gdrive/MyDrive/ucu_ml_research/data'\n",
        "file_list = os.listdir(path_to_data)\n",
        "\n",
        "paths = {'flownet2':['configs/flownet2/flownet2css_8x1_sfine_flyingthings3d_subset_384x768.py',\n",
        "                     '/content/gdrive/MyDrive/ucu_ml_research/pwcnet_ft_4x1_300k_sintel_final_384x768.pth'],\n",
        "         'pwc':['/content/mmflow/configs/pwcnet/pwcnet_ft_4x1_300k_sintel_384x768.py',\n",
        "                '/content/gdrive/MyDrive/ucu_ml_research/pwcnet_ft_4x1_300k_sintel_final_384x768.pth'],\n",
        "         'raft':['/content/mmflow/configs/raft/raft_8x2_100k_mixed_368x768.py',\n",
        "                     '/content/gdrive/MyDrive/ucu_ml_research/raft_8x2_100k_mixed_368x768.pth'],\n",
        "         'flownet':['/content/mmflow/configs/flownet/flownetc_8x1_sfine_sintel_384x448.py',\n",
        "                     '/content/gdrive/MyDrive/ucu_ml_research/flownetc_8x1_sfine_sintel_384x448.pth']}"
      ],
      "metadata": {
        "id": "ai7RUuMSiotf"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name):\n",
        "  model_paths = paths[model_name]\n",
        "  config_file = model_paths[0]\n",
        "  checkpoint_file = model_paths[1]\n",
        "  model = init_model(config_file, checkpoint_file, device=device)\n",
        "  return model"
      ],
      "metadata": {
        "id": "VqzTiE0Riozi"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('flownet2')\n",
        "\n",
        "clear_image = np.zeros((150,150,3))\n",
        "pos = (200, 200)\n",
        "\n",
        "def gauss(mean,sigma):\n",
        "     from random import uniform\n",
        "     from math import sqrt,log,pi,cos\n",
        "     a=uniform(0,1)\n",
        "     b=uniform(0,1)\n",
        "     x=sqrt(-2*log(a))*cos(2*pi*b)\n",
        "     return(x)\n",
        "\n",
        "def bruiter(image):\n",
        "  a,b,c=image.shape\n",
        "  for i in range(a):\n",
        "    for j in range(b):\n",
        "      image[i][j] += [gauss(0.5,0.01),gauss(0.5,0.01),gauss(0.5,0.01)]\n",
        "  image = abs(np.round(image*50)).astype(np.uint8)\n",
        "  return(image)\n",
        "\n",
        "def add_noise_to_img(image, noise, pos = pos):\n",
        "  image[pos[0]:pos[0]+noise.shape[0], pos[1]:pos[1]+noise.shape[1]] = noise\n",
        "  return image"
      ],
      "metadata": {
        "id": "jPz_HtXHkeUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69ed6ce-743b-42f1-b0d2-7bdce8732ec2"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-29 13:35:39,037 - mmflow - INFO - Freeze the parameters in FlowNetC\n",
            "2022-01-29 13:35:39,457 - mmflow - INFO - Freeze the parameters in FlowNetS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load checkpoint from local path: /content/gdrive/MyDrive/ucu_ml_research/pwcnet_ft_4x1_300k_sintel_final_384x768.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: encoder.layers.0.layers.0.conv.weight, encoder.layers.0.layers.0.conv.bias, encoder.layers.0.layers.1.conv.weight, encoder.layers.0.layers.1.conv.bias, encoder.layers.0.layers.2.conv.weight, encoder.layers.0.layers.2.conv.bias, encoder.layers.1.layers.0.conv.weight, encoder.layers.1.layers.0.conv.bias, encoder.layers.1.layers.1.conv.weight, encoder.layers.1.layers.1.conv.bias, encoder.layers.1.layers.2.conv.weight, encoder.layers.1.layers.2.conv.bias, encoder.layers.2.layers.0.conv.weight, encoder.layers.2.layers.0.conv.bias, encoder.layers.2.layers.1.conv.weight, encoder.layers.2.layers.1.conv.bias, encoder.layers.2.layers.2.conv.weight, encoder.layers.2.layers.2.conv.bias, encoder.layers.3.layers.0.conv.weight, encoder.layers.3.layers.0.conv.bias, encoder.layers.3.layers.1.conv.weight, encoder.layers.3.layers.1.conv.bias, encoder.layers.3.layers.2.conv.weight, encoder.layers.3.layers.2.conv.bias, encoder.layers.4.layers.0.conv.weight, encoder.layers.4.layers.0.conv.bias, encoder.layers.4.layers.1.conv.weight, encoder.layers.4.layers.1.conv.bias, encoder.layers.4.layers.2.conv.weight, encoder.layers.4.layers.2.conv.bias, encoder.layers.5.layers.0.conv.weight, encoder.layers.5.layers.0.conv.bias, encoder.layers.5.layers.1.conv.weight, encoder.layers.5.layers.1.conv.bias, encoder.layers.5.layers.2.conv.weight, encoder.layers.5.layers.2.conv.bias, decoder.post_processor.layers.0.conv.weight, decoder.post_processor.layers.0.conv.bias, decoder.post_processor.layers.1.conv.weight, decoder.post_processor.layers.1.conv.bias, decoder.post_processor.layers.2.conv.weight, decoder.post_processor.layers.2.conv.bias, decoder.post_processor.layers.3.conv.weight, decoder.post_processor.layers.3.conv.bias, decoder.post_processor.layers.4.conv.weight, decoder.post_processor.layers.4.conv.bias, decoder.post_processor.layers.5.conv.weight, decoder.post_processor.layers.5.conv.bias, decoder.post_processor.layers.6.weight, decoder.post_processor.layers.6.bias, decoder.decoders.level2.dense_net.layers.0.layers.conv.weight, decoder.decoders.level2.dense_net.layers.0.layers.conv.bias, decoder.decoders.level2.dense_net.layers.1.layers.conv.weight, decoder.decoders.level2.dense_net.layers.1.layers.conv.bias, decoder.decoders.level2.dense_net.layers.2.layers.conv.weight, decoder.decoders.level2.dense_net.layers.2.layers.conv.bias, decoder.decoders.level2.dense_net.layers.3.layers.conv.weight, decoder.decoders.level2.dense_net.layers.3.layers.conv.bias, decoder.decoders.level2.dense_net.layers.4.layers.conv.weight, decoder.decoders.level2.dense_net.layers.4.layers.conv.bias, decoder.decoders.level2.predict_layer.weight, decoder.decoders.level2.predict_layer.bias, decoder.decoders.level3.dense_net.layers.0.layers.conv.weight, decoder.decoders.level3.dense_net.layers.0.layers.conv.bias, decoder.decoders.level3.dense_net.layers.1.layers.conv.weight, decoder.decoders.level3.dense_net.layers.1.layers.conv.bias, decoder.decoders.level3.dense_net.layers.2.layers.conv.weight, decoder.decoders.level3.dense_net.layers.2.layers.conv.bias, decoder.decoders.level3.dense_net.layers.3.layers.conv.weight, decoder.decoders.level3.dense_net.layers.3.layers.conv.bias, decoder.decoders.level3.dense_net.layers.4.layers.conv.weight, decoder.decoders.level3.dense_net.layers.4.layers.conv.bias, decoder.decoders.level3.predict_layer.weight, decoder.decoders.level3.predict_layer.bias, decoder.decoders.level3.upflow_layer.weight, decoder.decoders.level3.upflow_layer.bias, decoder.decoders.level3.upfeat_layer.weight, decoder.decoders.level3.upfeat_layer.bias, decoder.decoders.level4.dense_net.layers.0.layers.conv.weight, decoder.decoders.level4.dense_net.layers.0.layers.conv.bias, decoder.decoders.level4.dense_net.layers.1.layers.conv.weight, decoder.decoders.level4.dense_net.layers.1.layers.conv.bias, decoder.decoders.level4.dense_net.layers.2.layers.conv.weight, decoder.decoders.level4.dense_net.layers.2.layers.conv.bias, decoder.decoders.level4.dense_net.layers.3.layers.conv.weight, decoder.decoders.level4.dense_net.layers.3.layers.conv.bias, decoder.decoders.level4.dense_net.layers.4.layers.conv.weight, decoder.decoders.level4.dense_net.layers.4.layers.conv.bias, decoder.decoders.level4.predict_layer.weight, decoder.decoders.level4.predict_layer.bias, decoder.decoders.level4.upflow_layer.weight, decoder.decoders.level4.upflow_layer.bias, decoder.decoders.level4.upfeat_layer.weight, decoder.decoders.level4.upfeat_layer.bias, decoder.decoders.level5.dense_net.layers.0.layers.conv.weight, decoder.decoders.level5.dense_net.layers.0.layers.conv.bias, decoder.decoders.level5.dense_net.layers.1.layers.conv.weight, decoder.decoders.level5.dense_net.layers.1.layers.conv.bias, decoder.decoders.level5.dense_net.layers.2.layers.conv.weight, decoder.decoders.level5.dense_net.layers.2.layers.conv.bias, decoder.decoders.level5.dense_net.layers.3.layers.conv.weight, decoder.decoders.level5.dense_net.layers.3.layers.conv.bias, decoder.decoders.level5.dense_net.layers.4.layers.conv.weight, decoder.decoders.level5.dense_net.layers.4.layers.conv.bias, decoder.decoders.level5.predict_layer.weight, decoder.decoders.level5.predict_layer.bias, decoder.decoders.level5.upflow_layer.weight, decoder.decoders.level5.upflow_layer.bias, decoder.decoders.level5.upfeat_layer.weight, decoder.decoders.level5.upfeat_layer.bias, decoder.decoders.level6.dense_net.layers.0.layers.conv.weight, decoder.decoders.level6.dense_net.layers.0.layers.conv.bias, decoder.decoders.level6.dense_net.layers.1.layers.conv.weight, decoder.decoders.level6.dense_net.layers.1.layers.conv.bias, decoder.decoders.level6.dense_net.layers.2.layers.conv.weight, decoder.decoders.level6.dense_net.layers.2.layers.conv.bias, decoder.decoders.level6.dense_net.layers.3.layers.conv.weight, decoder.decoders.level6.dense_net.layers.3.layers.conv.bias, decoder.decoders.level6.dense_net.layers.4.layers.conv.weight, decoder.decoders.level6.dense_net.layers.4.layers.conv.bias, decoder.decoders.level6.predict_layer.weight, decoder.decoders.level6.predict_layer.bias, decoder.decoders.level6.upflow_layer.weight, decoder.decoders.level6.upflow_layer.bias, decoder.decoders.level6.upfeat_layer.weight, decoder.decoders.level6.upfeat_layer.bias\n",
            "\n",
            "missing keys in source state_dict: flownetC.encoder.layers.0.layers.0.conv.weight, flownetC.encoder.layers.0.layers.0.conv.bias, flownetC.encoder.layers.1.layers.0.conv.weight, flownetC.encoder.layers.1.layers.0.conv.bias, flownetC.encoder.layers.2.layers.0.conv.weight, flownetC.encoder.layers.2.layers.0.conv.bias, flownetC.decoder.decoders.level2.pred_out.weight, flownetC.decoder.decoders.level2.pred_out.bias, flownetC.decoder.decoders.level3.pred_out.weight, flownetC.decoder.decoders.level3.pred_out.bias, flownetC.decoder.decoders.level3.deconv_out.deconvs.0.weight, flownetC.decoder.decoders.level3.deconv_out.deconvs.0.bias, flownetC.decoder.decoders.level3.upsample_pred.deconvs.0.weight, flownetC.decoder.decoders.level3.upsample_pred.deconvs.0.bias, flownetC.decoder.decoders.level4.pred_out.weight, flownetC.decoder.decoders.level4.pred_out.bias, flownetC.decoder.decoders.level4.deconv_out.deconvs.0.weight, flownetC.decoder.decoders.level4.deconv_out.deconvs.0.bias, flownetC.decoder.decoders.level4.upsample_pred.deconvs.0.weight, flownetC.decoder.decoders.level4.upsample_pred.deconvs.0.bias, flownetC.decoder.decoders.level5.pred_out.weight, flownetC.decoder.decoders.level5.pred_out.bias, flownetC.decoder.decoders.level5.deconv_out.deconvs.0.weight, flownetC.decoder.decoders.level5.deconv_out.deconvs.0.bias, flownetC.decoder.decoders.level5.upsample_pred.deconvs.0.weight, flownetC.decoder.decoders.level5.upsample_pred.deconvs.0.bias, flownetC.decoder.decoders.level6.pred_out.weight, flownetC.decoder.decoders.level6.pred_out.bias, flownetC.decoder.decoders.level6.deconv_out.deconvs.0.weight, flownetC.decoder.decoders.level6.deconv_out.deconvs.0.bias, flownetC.decoder.decoders.level6.upsample_pred.deconvs.0.weight, flownetC.decoder.decoders.level6.upsample_pred.deconvs.0.bias, flownetC.corr_encoder.layers.0.layers.0.conv.weight, flownetC.corr_encoder.layers.0.layers.0.conv.bias, flownetC.corr_encoder.layers.1.layers.0.conv.weight, flownetC.corr_encoder.layers.1.layers.0.conv.bias, flownetC.corr_encoder.layers.1.layers.1.conv.weight, flownetC.corr_encoder.layers.1.layers.1.conv.bias, flownetC.corr_encoder.layers.2.layers.0.conv.weight, flownetC.corr_encoder.layers.2.layers.0.conv.bias, flownetC.corr_encoder.layers.2.layers.1.conv.weight, flownetC.corr_encoder.layers.2.layers.1.conv.bias, flownetC.corr_encoder.layers.3.layers.0.conv.weight, flownetC.corr_encoder.layers.3.layers.0.conv.bias, flownetC.corr_encoder.layers.3.layers.1.conv.weight, flownetC.corr_encoder.layers.3.layers.1.conv.bias, flownetC.corr_encoder.conv_redir.conv.weight, flownetC.corr_encoder.conv_redir.conv.bias, flownetS1.encoder.layers.0.layers.0.conv.weight, flownetS1.encoder.layers.0.layers.0.conv.bias, flownetS1.encoder.layers.1.layers.0.conv.weight, flownetS1.encoder.layers.1.layers.0.conv.bias, flownetS1.encoder.layers.2.layers.0.conv.weight, flownetS1.encoder.layers.2.layers.0.conv.bias, flownetS1.encoder.layers.2.layers.1.conv.weight, flownetS1.encoder.layers.2.layers.1.conv.bias, flownetS1.encoder.layers.3.layers.0.conv.weight, flownetS1.encoder.layers.3.layers.0.conv.bias, flownetS1.encoder.layers.3.layers.1.conv.weight, flownetS1.encoder.layers.3.layers.1.conv.bias, flownetS1.encoder.layers.4.layers.0.conv.weight, flownetS1.encoder.layers.4.layers.0.conv.bias, flownetS1.encoder.layers.4.layers.1.conv.weight, flownetS1.encoder.layers.4.layers.1.conv.bias, flownetS1.encoder.layers.5.layers.0.conv.weight, flownetS1.encoder.layers.5.layers.0.conv.bias, flownetS1.encoder.layers.5.layers.1.conv.weight, flownetS1.encoder.layers.5.layers.1.conv.bias, flownetS1.decoder.decoders.level2.pred_out.weight, flownetS1.decoder.decoders.level2.pred_out.bias, flownetS1.decoder.decoders.level3.pred_out.weight, flownetS1.decoder.decoders.level3.pred_out.bias, flownetS1.decoder.decoders.level3.deconv_out.deconvs.0.weight, flownetS1.decoder.decoders.level3.deconv_out.deconvs.0.bias, flownetS1.decoder.decoders.level3.upsample_pred.deconvs.0.weight, flownetS1.decoder.decoders.level4.pred_out.weight, flownetS1.decoder.decoders.level4.pred_out.bias, flownetS1.decoder.decoders.level4.deconv_out.deconvs.0.weight, flownetS1.decoder.decoders.level4.deconv_out.deconvs.0.bias, flownetS1.decoder.decoders.level4.upsample_pred.deconvs.0.weight, flownetS1.decoder.decoders.level5.pred_out.weight, flownetS1.decoder.decoders.level5.pred_out.bias, flownetS1.decoder.decoders.level5.deconv_out.deconvs.0.weight, flownetS1.decoder.decoders.level5.deconv_out.deconvs.0.bias, flownetS1.decoder.decoders.level5.upsample_pred.deconvs.0.weight, flownetS1.decoder.decoders.level6.pred_out.weight, flownetS1.decoder.decoders.level6.pred_out.bias, flownetS1.decoder.decoders.level6.deconv_out.deconvs.0.weight, flownetS1.decoder.decoders.level6.deconv_out.deconvs.0.bias, flownetS1.decoder.decoders.level6.upsample_pred.deconvs.0.weight, flownetS2.encoder.layers.0.layers.0.conv.weight, flownetS2.encoder.layers.0.layers.0.conv.bias, flownetS2.encoder.layers.1.layers.0.conv.weight, flownetS2.encoder.layers.1.layers.0.conv.bias, flownetS2.encoder.layers.2.layers.0.conv.weight, flownetS2.encoder.layers.2.layers.0.conv.bias, flownetS2.encoder.layers.2.layers.1.conv.weight, flownetS2.encoder.layers.2.layers.1.conv.bias, flownetS2.encoder.layers.3.layers.0.conv.weight, flownetS2.encoder.layers.3.layers.0.conv.bias, flownetS2.encoder.layers.3.layers.1.conv.weight, flownetS2.encoder.layers.3.layers.1.conv.bias, flownetS2.encoder.layers.4.layers.0.conv.weight, flownetS2.encoder.layers.4.layers.0.conv.bias, flownetS2.encoder.layers.4.layers.1.conv.weight, flownetS2.encoder.layers.4.layers.1.conv.bias, flownetS2.encoder.layers.5.layers.0.conv.weight, flownetS2.encoder.layers.5.layers.0.conv.bias, flownetS2.encoder.layers.5.layers.1.conv.weight, flownetS2.encoder.layers.5.layers.1.conv.bias, flownetS2.decoder.decoders.level2.pred_out.weight, flownetS2.decoder.decoders.level2.pred_out.bias, flownetS2.decoder.decoders.level3.pred_out.weight, flownetS2.decoder.decoders.level3.pred_out.bias, flownetS2.decoder.decoders.level3.deconv_out.deconvs.0.weight, flownetS2.decoder.decoders.level3.deconv_out.deconvs.0.bias, flownetS2.decoder.decoders.level3.upsample_pred.deconvs.0.weight, flownetS2.decoder.decoders.level4.pred_out.weight, flownetS2.decoder.decoders.level4.pred_out.bias, flownetS2.decoder.decoders.level4.deconv_out.deconvs.0.weight, flownetS2.decoder.decoders.level4.deconv_out.deconvs.0.bias, flownetS2.decoder.decoders.level4.upsample_pred.deconvs.0.weight, flownetS2.decoder.decoders.level5.pred_out.weight, flownetS2.decoder.decoders.level5.pred_out.bias, flownetS2.decoder.decoders.level5.deconv_out.deconvs.0.weight, flownetS2.decoder.decoders.level5.deconv_out.deconvs.0.bias, flownetS2.decoder.decoders.level5.upsample_pred.deconvs.0.weight, flownetS2.decoder.decoders.level6.pred_out.weight, flownetS2.decoder.decoders.level6.pred_out.bias, flownetS2.decoder.decoders.level6.deconv_out.deconvs.0.weight, flownetS2.decoder.decoders.level6.deconv_out.deconvs.0.bias, flownetS2.decoder.decoders.level6.upsample_pred.deconvs.0.weight\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metric(a,b):\n",
        "  for i, j in zip(a,b):\n",
        "    i[pos[0]:pos[0]+clear_image.shape[0], pos[1]:pos[1]+clear_image.shape[1]] = 0\n",
        "    j[pos[0]:pos[0]+clear_image.shape[0], pos[1]:pos[1]+clear_image.shape[1]] = 0\n",
        "\n",
        "  difference_array = np.subtract(a, b)\n",
        "  squared_array = np.square(difference_array)\n",
        "  return squared_array.mean()\n",
        "  \n",
        "def get_results(draw = False, use_noise = False, save_path = None):\n",
        "  results = []\n",
        "\n",
        "  if use_noise:\n",
        "    noise = bruiter(clear_image)\n",
        "\n",
        "  for i in range(len(file_list)-1):\n",
        "    img = Image.open(path_to_data+'/'+file_list[i])\n",
        "    img2 = Image.open(path_to_data+'/'+file_list[i+1])\n",
        "\n",
        "    if draw:\n",
        "      draw = ImageDraw.Draw(img)\n",
        "      draw.rectangle((pos, (pos[0]+clear_image.shape[0], pos[1]+clear_image.shape[1])), fill=\"green\")\n",
        "\n",
        "      draw = ImageDraw.Draw(img2)\n",
        "      draw.rectangle((pos, (pos[0]+clear_image.shape[0], pos[1]+clear_image.shape[1])), fill=\"green\")\n",
        "\n",
        "    img = np.asarray(img)\n",
        "    img2 = np.asarray(img2)\n",
        "\n",
        "    if use_noise:\n",
        "      img.setflags(write=1)\n",
        "      img2.setflags(write=1)\n",
        "\n",
        "      img = add_noise_to_img(img, noise)\n",
        "      img2 = add_noise_to_img(img2, noise)\n",
        "    \n",
        "    result = inference_model(model, img, img2)\n",
        "    results.append(result)\n",
        "    if save_path:\n",
        "      visualize_flow(result, save_file=f'/content/gdrive/MyDrive/ucu_ml_research/{save_path}/img_{i}.png')\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "eImQCXxqoYp7"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clear_results = get_results(save_path='flownet2')"
      ],
      "metadata": {
        "id": "efHxYkQEpY99",
        "outputId": "5a39ee83-e50c-4fed-ee26-fa5c4e63f8ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_list = []\n",
        "for i in tqdm.trange(10):\n",
        "  noised_results = get_results(use_noise=True, save_path = 'flownet2_noised')\n",
        "\n",
        "  mse_list.append(calculate_metric(noised_results, clear_results)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6yWmoFnqsWp",
        "outputId": "c712e952-1b36-48cb-e40c-93f50d6fce06"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "100%|██████████| 10/10 [13:31<00:00, 81.12s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(mse_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SeHLBlCtZtM",
        "outputId": "539e2281-ab48-40c9-fb29-176a5e3d28d1"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0007075362"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "square_results = get_results(draw = True, save_path = 'flownet2_square')\n",
        "calculate_metric(clear_results, square_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kQIrU7stJlB",
        "outputId": "233b0e99-2dde-4369-9f25-2a360c534750"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73.69141"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "image_folder = '/content/gdrive/MyDrive/ucu_ml_research/data'\n",
        "image_folder_noised = '/content/gdrive/MyDrive/ucu_ml_research/pwc_noised'\n",
        "image_folder_clear = '/content/gdrive/MyDrive/ucu_ml_research/pwc_clear'\n",
        "\n",
        "video_name = '/content/gdrive/MyDrive/ucu_ml_research/pwc_examle.avi'\n",
        "\n",
        "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
        "images_noised = [img for img in os.listdir(image_folder_noised) if img.endswith(\".png\")]\n",
        "images_clear = [img for img in os.listdir(image_folder_clear) if img.endswith(\".png\")]\n",
        "\n",
        "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "height, width, layers = frame.shape\n",
        "\n",
        "video = cv2.VideoWriter(video_name, 0, 15, (width,height*3))\n",
        "\n",
        "for image, noise, clear in zip(images, images_noised, images_clear):\n",
        "\n",
        "  img_clear = cv2.imread(os.path.join(image_folder_clear, clear))\n",
        "  img_ori = cv2.imread(os.path.join(image_folder, image))\n",
        "  img_noised = cv2.imread(os.path.join(image_folder_noised, noise))\n",
        "\n",
        "  vis = np.concatenate((img_ori, img_clear, img_noised), axis=0)\n",
        "  video.write(vis)\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "video.release()"
      ],
      "metadata": {
        "id": "Sw_Lon9X9vL5"
      },
      "execution_count": 117,
      "outputs": []
    }
  ]
}